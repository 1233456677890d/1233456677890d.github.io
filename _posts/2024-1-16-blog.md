---
  layout: post
  title: Examining Zero-Shot Vulnerability Repair with Large Language Models
  categories: Papers
  description: 读论文
  keywords: ChatGPT, LLMs, papers
---
# Examining Zero-Shot Vulnerability Repair with Large Language Models
2023 IEEE Symposium on Security and Privacy (SP)


## introduction
提出的核心问题：用于生成代码的LLM可以用来**修复**代码的安全漏洞吗

研究目标：使用现成的LLM，为漏洞代码创建安全补丁，对单个文件的代码进行小幅度的修改。

研究方法：用现成的LLM进行zero-shot（0训练），来生成替代的安全代码

研究面临的问题：
1. LLM能否生成安全代码进行漏洞的修复？
2. prompt的上下文数量对LLM修复漏洞能力的影响
3. LLM修复漏洞面临的挑战
4. LLM修补漏洞的有效性

贡献：
1. 比较了prompt的编写和模型的设置对LLM生成代码的影响（第三章）
2. 评估了LLM在简单场景下修复的表现，效果很好（第四章）
3. 评估了LLM在真实场景下修复的表现，存在困难，不适合提供实际价值（第五章）
4. 开源了数据集和评估框架

## background
把自己训练的本地模型放在了background上
gpt2-csrc LLM：自己训练的一个本地模型，从debian最受欢迎的10000个包中收集c/c++代码数据，通过预处理得到17GB代码
* 分词：在源数据集上训练了一个BPE分词器，为英文文本调整，用较少的令牌表示源代码。
* LLM：用的NVIDIA Megatron代码库训练，36层，20个注意力头，最大序列长度1024），学习率为0.0001，权重衰减为0.01，采用余弦学习率衰减计划。模型训练了四个GPU月（在4×RTX8000 GPU上训练了一个月）
  
## prompt

prompt部分内容较少
* copliot输出的代码对prompt很敏感
* prompt的内容包括
  (i) 开头注释（例如，通知、变更历史）
  (ii) 导入和定义（例如，包声明、预处理器指令）
  (iii) 现有的代码和注释，可能与要完成的代码行相关
  (iv) 用户希望代码完成建议的文件中的位置。
* 源文件足够小的话，可以直接扔进模型中，如果比较大，需要在特定位置添加一些注释

## 简单环境下实验

* 实验阶段
  1. 对模型参数全面扫描，确定用于代码修复的典型参数
  2. 研究不同上下文的prompt对代码修复质量的影响
* 具体流程
![20240115002527.png](images/20240115002527.png)
  1. 批量合成漏洞程序数据集
   * 选取CVE：越界写（对应C程序）和SQL注入（对应python），各提供一个初始的写好的程序
   * 批量生成：指定程序开头，让LLM在不同温度下生成程序，通过CodeQL进行评估，再从中选取一些独特且易受攻击的的程序作为数据集
   * 不同温度：code-cushman-001和code-davinci-001为每个温度{0.00, 0.25, 0.50, 0.75, 1.00}和top p {0.00, 0.25, 0.50, 0.75, 1.00}的组合生成10个程序
   * 结果：生成了包含CWE-787（越界写）的95个独特的漏洞程序，以及包含CWE-89（SQL注入）的22个独特的漏洞程序
  2. 不同参数的LLM进行漏洞修复，确定最优参数
   * 使用简单的prompt，注释掉危险代码，将codeQL的提示也放在一起
   * 同上的温度和top p分别进行修补
   * 修补结果：在CWE-787场景中，22034个有效程序中有2.2%被修复。在CWE-89场景中，10796个有效程序中有29.6%被修复。
   ![20240116000728.png](images/20240116000728.png)
   * 结论：没有单一的温度/top p能最好地覆盖所有场景
   * 鉴于官方文档建议改变这些参数中的任何一个，而不是同时改变，最终选择将一组温度{0.00,0.25,0.50,0.75,1.00}设置为查询集合的参数，并将顶部p固定为1.00
  3. 编写更高的prompt和人工生成恶意代码
   * 编写了更多定制程序，覆盖MITRE top25列表的安全漏洞，5个c漏洞，2个python漏洞
   * 编写了5个模板，信息量不同，从直接删除漏洞函数，到详细的解释漏洞
     ![20240116214308.png](images/20240116214308.png)
   * 修补结论：每个恶意代码在至少一个模板+大模型的组合下被修补
   * 上下文模板结论：
     * 某些情况下低上下文模板优于高上下文模板(原始程序生成比程序修复效果更好)
     * 某些情况下高上下文模板效果更好（低上下文提示符无法提供足够多的功能信息，使大模型生成功能）
     * 高上下文模板能评价产生最佳结果，额外的技术细节有助于大模型生成代码
   * 大模型对比：codex生成结果比其他模型好
   ![20240116004246.png](images/20240116004246.png)
  4. 硬件代码：
   * 选取了两个verilog漏洞： codex效果没有c和python好
   * 上下文模板：低上下文的情况下，llm似乎表现得更好。模型倾向于“做正确的事情”。
## 真实环境下实验
* 选择真实漏洞：12个
  * 选择依据：漏洞要有poc，patch能针对在**单个文件**上，有对应的测试套件
  * 代码删减：真实世界的代码量过大，影响了模型的输入说出，因此要进行删减
    ![20240116212637.png](images/20240116212637.png)
    删减方式：保留#define，直接调到poc指出的漏洞函数处，如果仍然过长，则从上往下去除一些行数
  * 修补方式：注释存在漏洞的函数行，并添加文字提示LLM进行修补，修补之后的内容与原有内容进行组装（去除LLM提供的额外修改）。
    ![20240116213859.png](images/20240116213859.png)
    组装代码：LLM的返回和原始文件找到30个重叠字符（找不到则不断减少，如果5个重叠字符也不存在则将LLM生成内容直接放到最后），注释行多包含几个安全的函数行，便于产生重叠字符
  * 修补成功定义：当替换的代码导致编译的程序通过每个程序包含的功能测试并且不再因 ASAN/UBSAN输入而崩溃时，则认定为修复。
  * 修补结果：8/12个漏洞被修补（**在若干个温度和LLM的组合下，存在任何一个有效的输出即视作修补**），但有些会引入新的错误；openAI的模型优于其他模型，s.1和s.2的prompt模板效果更好
  ![20240116215839.png](images/20240116213859.png)
![20240116215857.png](images/20240116213859.png)
  
  * LLM修补失败的特征：需要大量的代码更改；尤其是需要添加的时候，LLM对上下文的理解收到限制
  * 实验总结：真实环节下LLM还不够可靠，且修补仅限于单个文件的单个位置，对安全错误要求局部化

## 个人评价
1. 研究核心：如何修复已知漏洞情况下的代码，需要已知漏洞，且有poc，限制比较多
2. 一个研究论点：LLMs在修补代码，和直接自己实现代码功能这两种情况下，后者更方便也效果更好
3. prompt编写较为简单：没有更细节的描述，prompt上下文多与少的对比效果令人怀疑
4. 无法处理多个文件，跨函数的漏洞：只是单纯的处理单个函数。
5. 以评估为主，没有产生一个完整的项目，另外是单纯使用了未经额外训练的公开LLM。