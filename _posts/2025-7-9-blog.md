---
  layout: post
  title: "Rescriber: Smaller-LLM-Powered User-Led Data Minimization for LLM-Based Chatbots"
  categories: Paper
  description: CHI ’25, Yokohama, Japan
  keywords: Paper, LLM, Privacy
---
# Rescriber: Smaller-LLM-Powered User-Led Data Minimization for LLM-Based Chatbots

**作者**: Felix Gruber, Neha Thota, Johann Schlör, Daniel Arp, Konrad Rieck  
**会议**: CHI ’25, Yokohama, Japan  
**DOI**: [10.1145/3706598.3713560](https://doi.org/10.1145/3706598.3713560)

---
## 摘要
基于 LLM 的对话代理的激增导致了可识别信息或敏感信息的过度泄露。然而，由于缺乏用户参与，现有技术无法提供可感知的控制，也无法考虑用户在隐私-效用权衡方面的个人偏好。为了弥补这一差距，我们设计、构建并评估了 Rescriber，这是一个浏览器扩展程序，它通过帮助用户检测和清理提示中的个人信息，支持基于 LLM 的对话代理中用户主导的数据最小化。我们的研究（N=Rescriber）表明，Rescriber 帮助用户减少了不必要的信息泄露，并解决了他们的隐私问题。用户对由 Llama3-8B 驱动的系统主观感受与 GPT-4o 系统相当。检测和清理的全面性和一致性是影响用户信任和感知保护的关键因素。我们的研究证实了基于 LLM 的、面向用户的设备端隐私控制的可行性，为应对人工智能的隐私和信任挑战提供了一种有前景的方法。

## 研究目的

- 提出一种新颖系统「Rescriber」，由小型 LLM 支持，以用户为中心，减少用户与大型聊天机器人之间的敏感数据暴露；
- 探讨一种低资源、用户主导的数据最小化策略；
- 验证其对隐私、任务完成度和用户体验的影响。

---
![20250604221215.png](/images/1752045503217-0.png)
## 系统结构概览：Rescriber 是什么？

- 核心理念：**在数据进入主 LLM 前进行预处理**；
- 架构组成：
  1. **小型本地 LLM**：用户端运行，用于检测并重写敏感数据；
  2. **主聊天机器人（如 ChatGPT）**：用户重写后的信息才会发送给主模型；
  3. **反转模块**（可选）：将主模型的输出映射回原始上下文。

---
![20250604222524.png](/images/1752045503217-1.png)
## 功能目标

- **用户控制数据重写程度**（从仅检测到自动重写）；
- 保护以下常见敏感信息：
  - 姓名、地址、财务信息、健康状况、登录凭证等；
- 用户可选择：
  - 是否执行替换；
  - 替换为哪种占位符；
  - 是否自动恢复原始输出。

---

## 实验方法与结果

### 实验设置：

- **参与者数**：80人  
- **测试任务**：8个常见 chatbot 交互场景（例如医疗建议、生活规划、技术支持等）；
- **比较系统**：
  - 无保护（baseline）
  - 单纯掩码
  - Rescriber（自动 + 手动两种模式）

### 核心发现：

| 维度         | Rescriber 表现          |
|--------------|--------------------------|
| 隐私保护     | 显著减少敏感信息暴露     |
| 用户体验     | 满意度高于掩码与无保护方式 |
| 任务完成度   | 几乎不影响任务完成质量     |

---

## 定性结果

### 6.1 隐私担忧，但为何仍然使用ChatGPT？

- 用户虽然对隐私问题有担忧，但由于LLM工具的高效性和便利性，许多用户依然选择使用这些工具。
- 用户在交互中容易分享敏感信息，主要是因为对隐私风险缺乏足够的认识或控制。

### 6.2 隐私信任的因素

- **透明性**：用户更加信任能够清晰解释数据使用和隐私政策的工具。
- **控制权**：用户希望能够完全控制自己分享的数据，并且能明确知道数据的去向。
  
### 6.3 采纳的因素

- **工具的实用性和便捷性**：如果工具能够提供足够的便捷性，用户愿意牺牲一定的隐私。
- **隐私保护措施**：那些采取积极隐私保护措施的工具更容易获得用户的信任并被广泛采用。

### 6.4 针对工具的策略

- **数据最小化策略**：一些用户通过删除聊天记录、分离账户等方式减少隐私泄露的风险。
- **隐私教育**：通过教育和学习，用户逐渐理解数据保护的意义，进而采取更多的隐私保护措施。

### 6.5 教育与学习过程

- 参与者表示，在使用过程中，他们逐渐通过工具的隐私声明、警示和提示来提升对数据隐私的认知。
- 教育过程对于提升用户对隐私管理的主动性和防范意识至关重要。

---

## 贡献总结

1. **提出 Rescriber 框架**：首次系统性展示用户主导的数据最小化方案；
2. **实证效果验证**：隐私保护与用户体验取得平衡；
3. **可复现开源实现**：提供 GitHub 项目与模型细节；
4. **强调用户参与隐私控制的重要性**。

---

## 实践与研究启示

- 可部署在客户端的小型 LLM 可有效降低隐私泄露风险；
- 用户偏好多样，系统应支持个性化隐私控制；
- 数据最小化应成为未来 LLM 应用中的默认选项，而非“附加功能”。

---