---
  layout: post
  title: Privacy Perceptions of Custom GPTs by Users and Creators
  categories: Paper
  description: CHI ’25, Yokohama, Japan
  keywords: Paper, LLM, Privacy
---
# Privacy Perceptions of Custom GPTs by Users and Creators

**作者**: Rongjun Ma, Caterina Maidhof, Juan Carlos Carrillo, Janne Lindqvist, Jose Such  
**会议**: CHI ’25, Yokohama, Japan  
**DOI**: [10.1145/3706598.3713540](https://doi.org/10.1145/3706598.3713540)

---

## 摘要

GPT 是基于 OpenAI 大型语言模型构建的定制化 LLM 应用程序。任何个人或组织无需编程技能即可使用和创建 GPT。然而，超过三百万个 GPT 的快速增长引发了严重的隐私担忧。为了探索用户和创作者的隐私视角，我们采访了 23 位创作经验各异的 GPT 用户。我们的研究结果揭示了用户和创作者角色之间的界限以及他们对 GPT 数据流的理解。参与者对数据在收集、处理和传播过程中的处理方式以及隐私法规的缺失表示担忧。创作者还担心专有知识的流失。为此，参与者采取了诸如自我审查输入、评估 GPT 操作以及最小化使用痕迹等措施。关注用户创作者的双重角色，我们发现专业知识和责任感塑造了隐私认知。基于这些洞察，我们提出了切实可行的建议，以改善数据透明度和平台监管。

## 研究目标

- 理解 GPT 用户和创建者对隐私的认知与担忧；
- 探索创建与使用者身份之间的角色模糊性对隐私看法的影响；
- 基于访谈提出改进 GPT 隐私保护的建议。

---

## 研究方法

- **方法**：23名参与者的半结构化访谈：我们从2024年6月至7月进行了23次半结构化访谈。采访是通过Microsoft团队进行的，范围为40至126分钟，平均为69分钟。每个参与者都收到了20欧元的亚马逊代金券，以赔偿其时间。
![20250604215843.png](/images/1751911181696-0.png)

- **角色覆盖**：终端用户、业余创作者、专业GPT创作者；
- **分析方法**：归纳+演绎主题分析（Atlas.ti 工具辅助）；
- **理论基础**：Solove 的隐私分类法 + 用户心理模型 + 人本隐私视角。

![20250604220145.png](/images/1751911181696-1.png)
---
## GPT使用情景三种分类

1. **基本型 GPT**：基础型 GPT 是使用 OpenAI 提供的内建功能创建的，无需编程即可通过勾选选项启用。创作者可设置提示词或上传领域知识（如法律文档），但用户数据不会对创作者开放。创作者只能看到总体对话次数和用户评分。
2. **动作型 GPT**：动作型 GPT 可以通过 HTTP API 接入外部第三方服务。API 由创作者配置并以 JSON 格式注册到 OpenAI。根据配置，创作者可能会获取用户信息并将其传输至外部服务。每个“Action”都需用户授权才能执行。
3. **登录型 GPT**：这类 GPT 在连接第三方服务时需用户登录（如 OAuth）。登录认证完成后，GPT 可通过令牌等方式执行操作。与场景二相同，每次操作都需要用户明确授权。


---

## 用户/创作者数据流心理模型（RQ1）

- 用户普遍 **缺乏对数据流的清晰认知**，表现为“希望而非确信”；
- 专业创作者 **理解更准确**，但对数据访问权利有限感到沮丧；
- 存在对第三方 API 滥用、OpenAI 与创作者权限混淆的担忧。

---

## 用户隐私担忧（RQ2）

基于 Solove 框架，隐私担忧分为：

- **UC1 数据收集**：担心敏感数据输入、被多方获取、不透明的数据用途；
- **UC2 数据处理**：担心生成用户画像、信息误用/泄露；
- **UC3 数据传播**：担忧意外暴露、GPT跨用户泄露、深度伪造风险；
- **UC4 监管缺失**：缺乏平台审核和政府法规保护；
- **CC1 知识泄露**（创作者特有）：担忧 Prompt 被抄袭、知识产权被侵犯。

---

## 用户与创作者应对策略（RQ2）

- **UP1 自我审查**：控制输入内容，避免敏感信息；
![20250604220402.png](/images/1751911181696-2.png)

- **UP2 GPT评估**：通过评价/使用记录判断可信度；
- **UP3 降低痕迹**：分离账户、删除记录、混淆信息；
- **UP4 隐私妥协**：承认风险换取便利或因“数字无力感”放弃抵抗；
- **CP1 知识保护**：隐藏 Prompt、屏蔽访问、设置私有；
- **CP2 提供隐私声明**：为用户/客户添加隐私条款，但缺乏平台支持。

---
## 用户-创作者角色交叉影响（RQ3）

- **双重身份**：创作者通常对平台结构理解更深入，减少部分担忧；
- **责任感增强**：创作者更关注用户隐私与合规义务；
- **信任悖论**：即便理解系统，也不一定信任其他创作者；
- **控制感增强**：创作者感到掌控力更强，从而降低隐私焦虑。

---

## 实践建议

- 提升 **GPT隐私透明度**：显示数据流动图、权限提示；
- 建议 **加强平台审核机制**：比如验证创作者身份；
- 鼓励 **用户教育**：提升普通用户对GPT内部逻辑的认知；
- 支持 **创作者隐私声明生成与管理** 工具。

---
